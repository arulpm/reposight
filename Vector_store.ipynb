{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ij678clcvWlt",
        "outputId": "04175018-f10e-493b-a6ae-36c55980a5bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index-embeddings-huggingface llama-index-vector-stores-chroma llama-index sentence-transformers --quiet --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PAzQsGxxw0s",
        "outputId": "64e0cf26-d22c-4a49-de31-0a5279792748"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/268.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m266.2/268.8 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "path = '/content/drive/MyDrive/bangkit/Data/dataset.csv'\n",
        "path_db= 'database'\n",
        "\n",
        "hf_key=\"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\"\n",
        "\n",
        "def truncate_text(text, max_words=512):\n",
        "    words = text.split()\n",
        "    return ' '.join(words[:max_words])\n",
        "\n",
        "# Check if the directory exists\n",
        "if not os.path.exists(path_db):\n",
        "    print(\"Proses membuat database txt...\")\n",
        "\n",
        "    # Read the CSV file\n",
        "    df = pd.read_csv(path)\n",
        "    df = df[0:3000]\n",
        "    df['abstract'] = df['abstract'].apply(lambda x: truncate_text(str(x), max_words=512))\n",
        "\n",
        "    # Create the directory\n",
        "    os.makedirs(path_db, exist_ok=True)\n",
        "\n",
        "    # Format and write the data to text files\n",
        "    for i, row in df.iterrows():\n",
        "        document = (f\"Judul: {row['title']}\\n\"\n",
        "                    f\"Author: {row['author']}\\n\"\n",
        "                    f\"Keyword: {row['keyword']}\\n\"\n",
        "                    f\"Type: {row['type']}\\n\"\n",
        "                    f\"url: {row['url']}\\n\"\n",
        "                    f\"Abstrak: {row['abstract']}\\n\")\n",
        "\n",
        "        # Define the file name and path\n",
        "        file_name = f\"research_{i}.txt\"\n",
        "        file_path = os.path.join(path_db, file_name)\n",
        "\n",
        "        # Write the document to a text file\n",
        "        with open(file_path, \"w\", encoding='utf-8') as f:\n",
        "            f.write(document)\n",
        "\n",
        "    print(f\"Database text files created successfully in '{path_db}' directory.\")\n",
        "else:\n",
        "    print(f\"The directory '{path_db}' already exists.\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2uUnEcNwVOW",
        "outputId": "841b0d68-dfa0-4092-b9bb-55c2a4890854"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proses membuat database txt...\n",
            "Database text files created successfully in 'database' directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.core import Settings\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
        "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
        "from llama_index.core import StorageContext\n",
        "import chromadb\n",
        "\n",
        "\n",
        "embed_model= \"/content/drive/MyDrive/bangkit/Model\"\n",
        "\n",
        "Settings.embed_model = HuggingFaceEmbedding(\n",
        "    model_name=embed_model,\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "\n",
        "text_splitter = SentenceSplitter(chunk_size=2000, chunk_overlap=10)\n",
        "\n",
        "# global\n",
        "from llama_index.core import Settings\n",
        "\n",
        "Settings.text_splitter = text_splitter\n",
        "\n",
        "documents = SimpleDirectoryReader(path_db).load_data()\n",
        "\n",
        "db = chromadb.PersistentClient(path=\"./chroma_db\")\n",
        "chroma_collection = db.get_or_create_collection(\"reposight\")\n",
        "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "\n",
        "index = VectorStoreIndex.from_documents(\n",
        "    documents, storage_context=storage_context, transformations=[text_splitter]\n",
        ")"
      ],
      "metadata": {
        "id": "-oy1Tgz-xc9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# To zip a folder\n",
        "# Replace 'folder_to_zip' with your folder name and 'output.zip' with desired zip file name\n",
        "shutil.make_archive('output', 'zip', 'folder_to_zip')\n",
        "\n",
        "# Alternatively, if you need more control, you can use zipfile module:\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "def zip_folder(folder_path, output_path):\n",
        "    with zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for root, dirs, files in os.walk(folder_path):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                arcname = os.path.relpath(file_path, folder_path)\n",
        "                zipf.write(file_path, arcname)\n",
        "\n",
        "# Usage\n",
        "zip_folder('/content/chroma_db', 'vector_store.zip')"
      ],
      "metadata": {
        "id": "WKq_SkCzxvKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sB0c8iWx0hNS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}